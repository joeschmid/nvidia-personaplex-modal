<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="/favicon.ico">
    <title>Web Demo of NVIDIA's PersonaPlex running on Modal</title>
    <style>
        * {
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            background: white;
            border-radius: 16px;
            padding: 30px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }

        h1 {
            color: #333;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .subtitle {
            color: #666;
            margin-bottom: 30px;
        }

        .form-group {
            margin-bottom: 20px;
        }

        label {
            display: block;
            font-weight: 600;
            margin-bottom: 8px;
            color: #444;
        }

        select, input[type="text"], input[type="password"], textarea {
            width: 100%;
            padding: 12px;
            font-size: 16px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            transition: border-color 0.2s;
        }

        select:focus, input:focus, textarea:focus {
            outline: none;
            border-color: #667eea;
        }

        textarea {
            min-height: 80px;
            resize: vertical;
        }

        .button-group {
            display: flex;
            gap: 10px;
            margin: 30px 0;
        }

        button {
            padding: 14px 28px;
            font-size: 16px;
            font-weight: 600;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.2s;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .btn-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-primary:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
        }

        .btn-secondary {
            background: #f0f0f0;
            color: #333;
        }

        .btn-secondary:hover:not(:disabled) {
            background: #e0e0e0;
        }

        .btn-danger {
            background: #e74c3c;
            color: white;
        }

        .btn-danger:hover:not(:disabled) {
            background: #c0392b;
        }

        #status {
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
            font-weight: 500;
            transition: all 0.3s;
        }

        .status-ready {
            background: #f8f9fa;
            color: #666;
        }

        .status-connecting {
            background: #fff3cd;
            color: #856404;
        }

        .status-connected {
            background: #d4edda;
            color: #155724;
        }

        .status-error {
            background: #f8d7da;
            color: #721c24;
        }

        .status-speaking {
            background: #cce5ff;
            color: #004085;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        #transcript {
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 15px;
            margin: 20px 0;
            background: #fafafa;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 14px;
            line-height: 1.6;
        }

        .transcript-ai {
            color: #667eea;
        }

        .transcript-user {
            color: #27ae60;
            font-weight: 700;
            display: block;
            margin-top: 8px;
        }

        .visualizer {
            height: 60px;
            background: #1a1a2e;
            border-radius: 8px;
            margin: 20px 0;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 3px;
            padding: 0 20px;
        }

        .visualizer-bar {
            width: 4px;
            background: linear-gradient(to top, #667eea, #764ba2);
            border-radius: 2px;
            transition: height 0.05s;
        }

        .info-box {
            background: #e8f4fd;
            border-left: 4px solid #667eea;
            padding: 15px;
            border-radius: 0 8px 8px 0;
            margin: 20px 0;
        }

        .info-box h3 {
            margin: 0 0 10px 0;
            color: #333;
        }

        .info-box ul {
            margin: 0;
            padding-left: 20px;
        }

        .info-box li {
            margin: 5px 0;
            color: #555;
        }

        .warning-box {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            border-radius: 0 8px 8px 0;
            margin: 20px 0;
        }

        .warning-box p {
            margin: 0;
            color: #856404;
        }

        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Web Demo of NVIDIA's PersonaPlex running on Modal</h1>
        <p class="subtitle">Real-time voice-to-voice conversation with customizable AI personas</p>

        <div class="form-group">
            <label for="voice">Voice</label>
            <select id="voice">
                <option value="NATF2">Natural Female (NATF2)</option>
                <option value="NATM2">Natural Male (NATM2)</option>
                <option value="VARF0">Variety Female (VARF0)</option>
                <option value="VARM0">Variety Male (VARM0)</option>
            </select>
        </div>

        <div class="form-group">
            <label for="textPrompt">Persona Prompt</label>
            <textarea id="textPrompt" placeholder="Describe the AI's personality...">You are a helpful and friendly assistant. Answer questions clearly and concisely. Be warm and engaging in conversation.</textarea>
        </div>

        <div class="button-group">
            <button id="startBtn" class="btn-primary" onclick="startChat()">
                üé§ Start Talking
            </button>
            <button id="stopBtn" class="btn-danger" onclick="stopChat()" disabled>
                ‚èπÔ∏è Stop
            </button>
        </div>

        <div id="status" class="status-ready">
            Status: Ready to connect
        </div>

        <div class="visualizer" id="visualizer">
            <!-- Audio visualizer bars will be added by JS -->
        </div>

        <label>Transcript</label>
        <div id="transcript">
            <em>Conversation transcript will appear here...</em>
        </div>

        <div class="info-box">
            <h3>üí° Tips</h3>
            <ul>
                <li>Allow microphone access when prompted</li>
                <li>Speak naturally - the AI responds in real-time</li>
                <li>Try different voices and persona prompts</li>
                <li>Use Chrome or Firefox for best compatibility</li>
            </ul>
        </div>
    </div>

    <!-- Opus encoder (works in all browsers via WebAssembly) -->
    <script src="https://cdn.jsdelivr.net/npm/opus-recorder@8.0.5/dist/recorder.min.js"></script>
    <!-- Opus decoder uses a Web Worker from opus-recorder -->

    <script>
        // =========================================================================
        // PersonaPlex WebSocket Client with Opus Audio
        // Encoding: opus-recorder library (WebAssembly, works in all browsers)
        // Decoding: opus-recorder decoderWorker (WebAssembly Web Worker)
        // Based on NVIDIA PersonaPlex reference implementation
        // =========================================================================

        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let analyserNode = null;
        let isConnected = false;
        let opusRecorder = null;
        let decoderWorker = null;

        // PersonaPlex uses 24kHz sample rate
        const SAMPLE_RATE = 24000;
        const CHANNELS = 1;

        // Audio playback queue
        let nextPlayTime = 0;

        // Initialize audio visualizer
        function initVisualizer() {
            const visualizer = document.getElementById('visualizer');
            visualizer.innerHTML = '';
            for (let i = 0; i < 32; i++) {
                const bar = document.createElement('div');
                bar.className = 'visualizer-bar';
                bar.style.height = '4px';
                visualizer.appendChild(bar);
            }
        }

        function updateVisualizerFromAnalyser() {
            if (!analyserNode || !isConnected) {
                const bars = document.querySelectorAll('.visualizer-bar');
                bars.forEach(bar => bar.style.height = '4px');
                return;
            }

            const dataArray = new Uint8Array(analyserNode.frequencyBinCount);
            analyserNode.getByteFrequencyData(dataArray);

            const bars = document.querySelectorAll('.visualizer-bar');
            const step = Math.floor(dataArray.length / bars.length);
            bars.forEach((bar, i) => {
                const value = dataArray[i * step] / 255;
                const height = Math.max(4, value * 50);
                bar.style.height = `${height}px`;
            });

            if (isConnected) {
                requestAnimationFrame(updateVisualizerFromAnalyser);
            }
        }

        function setStatus(message, statusClass = 'status-ready') {
            const statusEl = document.getElementById('status');
            statusEl.textContent = `Status: ${message}`;
            statusEl.className = statusClass;
        }

        function appendTranscript(text, isAI = true) {
            const transcript = document.getElementById('transcript');
            if (transcript.innerHTML.includes('<em>')) {
                transcript.innerHTML = '';
            }

            const span = document.createElement('span');
            span.className = isAI ? 'transcript-ai' : 'transcript-user';
            span.textContent = text;
            transcript.appendChild(span);
            transcript.scrollTop = transcript.scrollHeight;
        }


        // Create a warmup BOS (Beginning of Stream) page to initialize the decoder
        // This is required by opus-recorder's decoder to set up internal buffers
        function createWarmupBosPage() {
            // OpusHead: "OpusHead" + version(1) + channels(1) + preskip(2) + samplerate(4) + gain(2) + mapping(1)
            const opusHead = new Uint8Array([
                0x4F, 0x70, 0x75, 0x73, 0x48, 0x65, 0x61, 0x64, // "OpusHead"
                0x01,       // Version 1
                0x01,       // 1 channel (mono)
                0x38, 0x01, // Pre-skip: 312 samples (little-endian)
                0x80, 0xBB, 0x00, 0x00, // Sample rate: 48000 Hz (little-endian)
                0x00, 0x00, // Output gain: 0
                0x00,       // Channel mapping: 0 (mono/stereo)
            ]);

            // Ogg page header
            const pageHeader = new Uint8Array([
                0x4F, 0x67, 0x67, 0x53, // "OggS" magic
                0x00,       // Version 0
                0x02,       // BOS flag (Beginning of Stream)
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // Granule position: 0
                0x01, 0x00, 0x00, 0x00, // Stream serial: 1
                0x00, 0x00, 0x00, 0x00, // Page sequence: 0
                0x00, 0x00, 0x00, 0x00, // CRC (decoder doesn't check)
                0x01,       // 1 segment
                0x13,       // Segment size: 19 bytes (OpusHead)
            ]);

            // Combine header and OpusHead
            const bosPage = new Uint8Array(pageHeader.length + opusHead.length);
            bosPage.set(pageHeader, 0);
            bosPage.set(opusHead, pageHeader.length);

            return bosPage;
        }

        async function initOpusDecoder() {
            // Use opus-recorder's decoderWorker (same approach as NVIDIA PersonaPlex)
            // Worker and WASM files are served from /static/
            try {
                decoderWorker = new Worker('/static/decoderWorker.min.js');

                decoderWorker.onmessage = (e) => {
                    // Worker sends decoded PCM data as an array of Float32Array(s)
                    if (!e.data) return;
                    if (Array.isArray(e.data)) {
                        const mono = e.data[0];
                        if (mono && mono.length > 0) {
                            handleDecodedAudio(mono);
                        }
                        return;
                    }
                    if (e.data.length > 0) {
                        handleDecodedAudio(e.data);
                    }
                };

                decoderWorker.onerror = (e) => {
                    console.error('Decoder worker error:', e);
                };

                // Initialize the decoder worker
                // Opus internally decodes at 48kHz, then we resample to 24kHz for output
                decoderWorker.postMessage({
                    command: 'init',
                    bufferLength: 4096,  // Larger buffer for smoother output
                    decoderSampleRate: 48000,  // Opus always decodes at 48kHz
                    outputBufferSampleRate: SAMPLE_RATE,  // Resample to 24kHz
                    resampleQuality: 3,
                });

                console.log('opus-recorder decoderWorker initialized');

                // Give worker time to initialize WASM
                // The server will send proper Ogg BOS headers, so no need for warmup
                await new Promise(resolve => setTimeout(resolve, 500));

                return true;
            } catch (e) {
                console.error('Failed to init decoder worker:', e);
                return false;
            }
        }

        let audioPacketCount = 0;
        let decodedPacketCount = 0;

        function handleDecodedAudio(pcmData) {
            // Called when decoder worker sends decoded PCM (Float32Array)
            decodedPacketCount++;
            if (decodedPacketCount <= 5) {
                console.log(`Decoded audio packet #${decodedPacketCount}: samples=${pcmData?.length}`);
            }
            if (pcmData && pcmData.length > 0) {
                playPCM(pcmData, SAMPLE_RATE);
            }
        }

        function playPCM(pcmData, sampleRate = 48000) {
            if (!audioContext || pcmData.length === 0) return;

            // Create audio buffer at the decoded sample rate
            // opus-stream-decoder outputs at 48kHz, AudioContext will resample automatically
            const audioBuffer = audioContext.createBuffer(1, pcmData.length, sampleRate);
            audioBuffer.getChannelData(0).set(pcmData);

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);

            // Schedule playback
            const now = audioContext.currentTime;
            if (nextPlayTime < now) {
                nextPlayTime = now;
            }

            source.start(nextPlayTime);
            nextPlayTime += audioBuffer.duration;

            source.onended = () => {
                if (!isConnected) return;
                if (audioContext && audioContext.currentTime >= nextPlayTime - 0.1) {
                    setStatus('Connected - Speak now!', 'status-connected');
                }
            };
        }

        async function startChat() {
            try {
                setStatus('Initializing audio...', 'status-connecting');

                // Reset debug counters
                audioPacketCount = 0;
                decodedPacketCount = 0;

                // Initialize audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: SAMPLE_RATE
                });

                // Initialize Opus decoder
                await initOpusDecoder();

                // Get microphone access
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: SAMPLE_RATE,
                        channelCount: CHANNELS,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                    }
                });

                // Set up analyser for visualization
                const source = audioContext.createMediaStreamSource(mediaStream);
                analyserNode = audioContext.createAnalyser();
                analyserNode.fftSize = 256;
                source.connect(analyserNode);

                setStatus('Connecting to server...', 'status-connecting');

                // Build WebSocket URL (auth is handled by cookie)
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const host = window.location.host;
                const voice = document.getElementById('voice').value;
                const textPrompt = encodeURIComponent(document.getElementById('textPrompt').value);

                const wsUrl = `${protocol}//${host}/ws/chat?voice_prompt=${voice}&text_prompt=${textPrompt}&seed=-1`;

                ws = new WebSocket(wsUrl);
                ws.binaryType = 'arraybuffer';

                ws.onopen = () => {
                    console.log('WebSocket connected');
                    setStatus('Waiting for handshake...', 'status-connecting');
                };

                ws.onmessage = async (event) => {
                    const data = new Uint8Array(event.data);
                    if (data.length === 0) return;

                    const kind = data[0];
                    const payload = data.slice(1);

                    if (kind === 0) {
                        // Handshake received
                        console.log('Handshake received, starting audio capture');
                        isConnected = true;
                        setStatus('Connected - Speak now!', 'status-connected');
                        startOpusRecorder();
                        updateVisualizerFromAnalyser();
                        document.getElementById('startBtn').disabled = true;
                        document.getElementById('stopBtn').disabled = false;
                    } else if (kind === 1) {
                        // Audio data (Opus encoded)
                        handleIncomingAudio(payload);
                    } else if (kind === 2) {
                        // Text token
                        const text = new TextDecoder().decode(payload);
                        appendTranscript(text, true);
                        setStatus('AI speaking...', 'status-speaking');
                    } else if (kind === 3) {
                        // User transcript text
                        const text = new TextDecoder().decode(payload);
                        appendTranscript(text, false);
                    }
                };

                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    setStatus('Connection error', 'status-error');
                };

                ws.onclose = (event) => {
                    console.log('WebSocket closed:', event.code, event.reason);
                    isConnected = false;
                    stopOpusRecorder();

                    if (event.code === 4001) {
                        setStatus('Not authenticated - please login again', 'status-error');
                    } else {
                        setStatus('Disconnected', 'status-ready');
                    }

                    document.getElementById('startBtn').disabled = false;
                    document.getElementById('stopBtn').disabled = true;
                };

            } catch (error) {
                console.error('Error starting chat:', error);
                setStatus(`Error: ${error.message}`, 'status-error');
            }
        }

        function startOpusRecorder() {
            if (!mediaStream) return;

            // Configure opus-recorder similar to NVIDIA PersonaPlex
            // https://github.com/chris-rudmin/opus-recorder
            const recorderConfig = {
                encoderPath: 'https://cdn.jsdelivr.net/npm/opus-recorder@8.0.5/dist/encoderWorker.min.js',
                encoderSampleRate: SAMPLE_RATE,
                encoderFrameSize: 20,           // 20ms frames
                maxFramesPerPage: 1,            // Send each frame immediately
                numberOfChannels: CHANNELS,
                encoderApplication: 2049,       // VOIP mode (2049) - optimized for speech
                encoderComplexity: 0,           // Low complexity for speed
                resampleQuality: 3,
                streamPages: true,              // Stream as we record
                sourceNode: audioContext.createMediaStreamSource(mediaStream),
            };

            console.log('Initializing opus-recorder with config:', recorderConfig);

            opusRecorder = new Recorder(recorderConfig);

            opusRecorder.ondataavailable = (opusData) => {
                if (!isConnected || !ws || ws.readyState !== WebSocket.OPEN) return;

                // Build message: [0x01, ...opus_data]
                const message = new Uint8Array(1 + opusData.length);
                message[0] = 0x01;  // audio kind
                message.set(opusData, 1);

                try {
                    ws.send(message);
                } catch (e) {
                    console.error('Error sending audio:', e);
                }
            };

            opusRecorder.onstart = () => {
                console.log('Opus recorder started');
            };

            opusRecorder.onstop = () => {
                console.log('Opus recorder stopped');
            };

            opusRecorder.start().catch(e => {
                console.error('Failed to start opus recorder:', e);
                setStatus('Failed to start audio recording', 'status-error');
            });
        }

        function stopOpusRecorder() {
            if (opusRecorder) {
                try {
                    opusRecorder.stop();
                } catch (e) {
                    console.error('Error stopping recorder:', e);
                }
                opusRecorder = null;
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            analyserNode = null;
        }

        function handleIncomingAudio(opusData) {
            if (!audioContext || opusData.length === 0) return;

            audioPacketCount++;
            if (audioPacketCount <= 10) {
                // Check for OggS magic header and parse page info
                const hasOggS = opusData.length >= 4 &&
                    opusData[0] === 0x4F && opusData[1] === 0x67 &&
                    opusData[2] === 0x67 && opusData[3] === 0x53;

                let pageInfo = '';
                if (hasOggS && opusData.length >= 27) {
                    const headerType = opusData[5];
                    const pageIndex = opusData[18] | (opusData[19] << 8) | (opusData[20] << 16) | (opusData[21] << 24);
                    const isBOS = (headerType & 2) !== 0;
                    const isEOS = (headerType & 4) !== 0;
                    pageInfo = ` headerType=${headerType}, pageIndex=${pageIndex}, BOS=${isBOS}, EOS=${isEOS}`;
                }
                console.log(`Received audio packet #${audioPacketCount}: size=${opusData.length}, hasOggS=${hasOggS}${pageInfo}`);
            }

            // Send to decoder worker
            if (decoderWorker) {
                try {
                    // Copy the data since we're transferring the buffer
                    const dataCopy = new Uint8Array(opusData);
                    decoderWorker.postMessage({
                        command: 'decode',
                        pages: dataCopy
                    }, [dataCopy.buffer]);
                } catch (e) {
                    console.error('decoder worker error:', e);
                }
            } else {
                console.warn('No decoder worker available to decode audio');
            }
        }

        function stopChat() {
            isConnected = false;

            if (ws) {
                ws.close();
                ws = null;
            }

            stopOpusRecorder();

            if (decoderWorker) {
                try {
                    decoderWorker.terminate();
                } catch (e) {}
                decoderWorker = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            nextPlayTime = 0;

            setStatus('Disconnected', 'status-ready');
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', () => {
            initVisualizer();

            // Check for WebSocket support
            if (!('WebSocket' in window)) {
                setStatus('WebSocket not supported in this browser', 'status-error');
                document.getElementById('startBtn').disabled = true;
            }

            // Check for getUserMedia support
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                setStatus('Microphone access not supported', 'status-error');
                document.getElementById('startBtn').disabled = true;
            }

            // Check for opus-recorder
            if (typeof Recorder === 'undefined') {
                console.error('opus-recorder not loaded!');
                setStatus('Audio encoder not available', 'status-error');
                document.getElementById('startBtn').disabled = true;
            } else {
                console.log('opus-recorder loaded successfully');
            }

            // Decoder worker will be created on demand
            console.log('Decoder will use opus-recorder decoderWorker');
        });

        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            stopChat();
        });
    </script>
</body>
</html>
